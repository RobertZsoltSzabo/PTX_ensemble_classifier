{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szabo\\anaconda3\\envs\\lung_us\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize, CenterCrop\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "RESIZED_SIZE = 256\n",
    "TRAIN_ROOT = 'd:/Data/PTX/train'\n",
    "VAL_ROOT = 'd:/Data/PTX/validation'\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Resize(size=(RESIZED_SIZE, RESIZED_SIZE), antialias=True),\n",
    "    CenterCrop(size=(RESIZED_SIZE, RESIZED_SIZE))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=TRAIN_ROOT, transform=transforms)\n",
    "val_dataset = ImageFolder(root=VAL_ROOT, transform=transforms)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              )\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, loss_fn, optimizer, epochs=10, device='cpu', log_experiment=True):\n",
    "    if log_experiment:\n",
    "        val_loss_history = []\n",
    "        val_acc_history = []\n",
    "        artifact = wandb.Artifact('weights', type='model')\n",
    "        \n",
    "        run = wandb.init(\n",
    "            project=\"PTX\",\n",
    "            config={\n",
    "                \"model\": model_name,\n",
    "                \"epochs\": epochs,\n",
    "                \"batch_size\": BATCH_SIZE,\n",
    "                \"droupout\": DROPOUT_RATE,\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"training_image_size\": RESIZED_SIZE\n",
    "            })\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "        train_loss, train_acc = train_epoch(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        print(f'train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}')\n",
    "        val_loss, val_acc = test_epoch(model, val_dataloader, loss_fn, device)\n",
    "        print(f'val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}')\n",
    "        if log_experiment:\n",
    "            val_loss_history.append(val_loss)\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            if val_acc == max(val_acc_history) and val_loss == min(val_loss_history):\n",
    "                torch.save(model.state_dict(), 'best.pt')            \n",
    "\n",
    "            wandb.log({'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), 'last.pt')\n",
    "\n",
    "    if log_experiment:\n",
    "        artifact.add_file('last.pt')\n",
    "        artifact.add_file('best.pt')\n",
    "        artifact.save()\n",
    "        run.log_artifact(artifact)\n",
    "        run.finish()\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    train_loss /= size\n",
    "    correct /= size\n",
    "    return train_loss, correct\n",
    "\n",
    "def test_epoch(model, dataloader, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    return test_loss, correct\n",
    "\n",
    "def crossvalidate_all_models(models, folds, dataset, loss_fn, lr, epochs=10, device='cpu', log_experiment=True):\n",
    "    print(f'Starting k-fold cross validation for {epochs} epochs')\n",
    "    total_size = len(dataset)\n",
    "    split_size = total_size // folds\n",
    "\n",
    "    for model in models:\n",
    "        print(f'Cross validating {model.__class__.__name__}')\n",
    "        for fold_nr in range(folds):            \n",
    "            train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [total_size - split_size, split_size])\n",
    "\n",
    "            train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True)\n",
    "\n",
    "            val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False)\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            train(model=model.to(device),\n",
    "                train_dataloader=train_dataloader,\n",
    "                val_dataloader=val_dataloader,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                epochs=epochs,\n",
    "                device=device,\n",
    "                log_experiment=log_experiment)\n",
    "\n",
    "def train_all_models(models, train_dataset, val_dataloader, loss_fn, lr, epochs=10, device='cpu', log_experiment=True):\n",
    "    print(f'Starting ensemble model training for {epochs} epochs')\n",
    "    for model in models:\n",
    "        print(f'Training {model.__class__.__name__}')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        train(model=model.to(device),\n",
    "              train_dataloader=train_dataloader,\n",
    "              val_dataloader=val_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              optimizer=optimizer,\n",
    "              epochs=epochs,\n",
    "              device=device,\n",
    "              log_experiment=log_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validates a model on val_dataloader, and displays the results\n",
    "def validate(model, val_dataloader, device='cpu'):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loss, acc = test_epoch(model, val_dataloader, loss_fn, device)\n",
    "    print(f'loss: {loss:.4f}, acc: {acc:.4f}')\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szabo\\anaconda3\\envs\\lung_us\\Lib\\site-packages\\timm\\models\\_factory.py:114: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "model_names = ['resnet50', 'inception_v3', 'inception_resnet_v2', 'xception', 'vgg16']\n",
    "n_classes = 3\n",
    "DROPOUT_RATE = 0.5\n",
    "\n",
    "timm_models = [timm.create_model(model_name,\n",
    "                                 pretrained=True,\n",
    "                                 num_classes=n_classes,\n",
    "                                 drop_rate=DROPOUT_RATE) for model_name in model_names]\n",
    "\n",
    "for model in timm_models:\n",
    "    model.reset_classifier(3, 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ensemble model training for 15 epochs\n",
      "Training NoneType\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Repos\\PTX_ensemble_classifier\\TEST_train.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m log \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_all_models(models\u001b[39m=\u001b[39;49mtimm_models,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                  train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                  val_dataloader\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                  loss_fn\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mCrossEntropyLoss(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                  lr\u001b[39m=\u001b[39;49mLEARNING_RATE,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                  epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                  device\u001b[39m=\u001b[39;49mDEVICE,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                  log_experiment\u001b[39m=\u001b[39;49mlog)\n",
      "\u001b[1;32md:\\Repos\\PTX_ensemble_classifier\\TEST_train.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     train(model\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m           train_dataloader\u001b[39m=\u001b[39mtrain_dataloader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m           val_dataloader\u001b[39m=\u001b[39mval_dataloader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m           device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/PTX_ensemble_classifier/TEST_train.ipynb#W4sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m           log_experiment\u001b[39m=\u001b[39mlog_experiment)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-4\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "log = True\n",
    "\n",
    "train_all_models(models=timm_models,\n",
    "                 train_dataloader=train_dataloader,\n",
    "                 val_dataloader=val_dataloader,\n",
    "                 loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                 lr=LEARNING_RATE,\n",
    "                 epochs=EPOCHS,\n",
    "                 device=DEVICE,\n",
    "                 log_experiment=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss: 0.0237, train_acc: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:13<03:03, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0310, val_acc: 0.6389\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train_loss: 0.0124, train_acc: 0.8617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:23<02:28, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0205, val_acc: 0.7500\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train_loss: 0.0082, train_acc: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:33<02:11, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0068, val_acc: 0.9306\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "train_loss: 0.0084, train_acc: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:44<01:57, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0044, val_acc: 0.9583\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "train_loss: 0.0087, train_acc: 0.8995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:54<01:45, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0016, val_acc: 0.9722\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "train_loss: 0.0073, train_acc: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:04<01:34, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0009, val_acc: 1.0000\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "train_loss: 0.0115, train_acc: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:14<01:23, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0017, val_acc: 0.9722\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "train_loss: 0.0079, train_acc: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [01:25<01:12, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0014, val_acc: 0.9722\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "train_loss: 0.0072, train_acc: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:35<01:02, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0051, val_acc: 0.9444\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "train_loss: 0.0074, train_acc: 0.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [01:46<00:52, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0014, val_acc: 0.9722\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss: 0.0060, train_acc: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [01:56<00:41, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0090, val_acc: 0.9167\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "train_loss: 0.0097, train_acc: 0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [02:07<00:31, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0015, val_acc: 0.9861\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "train_loss: 0.0117, train_acc: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [02:18<00:21, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0022, val_acc: 0.9722\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "train_loss: 0.0068, train_acc: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [02:28<00:10, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0041, val_acc: 0.9306\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "train_loss: 0.0061, train_acc: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [02:39<00:00, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0018, val_acc: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-4\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model = feature_extractor_resnet.to(DEVICE)\n",
    "log = False\n",
    "\n",
    "\n",
    "train(model=model,\n",
    "      train_dataloader=train_dataloader,\n",
    "      val_dataloader=val_dataloader,\n",
    "      loss_fn=loss_fn,\n",
    "      optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),\n",
    "      epochs=EPOCHS,\n",
    "      device=DEVICE,\n",
    "      log_experiment=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam_overlay(image, gradcam, colormap='jet', opacity=0.2):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(gradcam, cmap=colormap, alpha=opacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded resnet50 successfully\n",
      "Loaded xception successfully\n",
      "Loaded inception_v3 successfully\n",
      "Loaded inception_resnet_v2 successfully\n",
      "Loaded vgg16 successfully\n"
     ]
    }
   ],
   "source": [
    "model_names = ['resnet50', 'xception', 'inception_v3', 'inception_resnet_v2', 'vgg16']\n",
    "model_weights = [f'weights/{model_name}.pt' for model_name in model_names]\n",
    "model_target_layers = ['layer4.2.act3', 'act4', 'Mixed_7c.branch_pool.bn.act', 'conv2d_7b.bn.act', 'features.29']\n",
    "\n",
    "models = [timm.create_model(model_name,\n",
    "                            pretrained=True,\n",
    "                            num_classes=3,\n",
    "                            drop_rate=0.5) for model_name in model_names]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.load_state_dict(torch.load(model_weights[i]))\n",
    "    print(f'Loaded {model_names[i]} successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from monai.visualize.class_activation_maps import GradCAM, GradCAMpp\n",
    "\n",
    "n = 15\n",
    "plt.figure(figsize=(15, 40))\n",
    "\n",
    "test_model = feature_extractor_resnet\n",
    "test_model.to('cpu')\n",
    "gradcam = GradCAM(nn_module=test_model, target_layers='layer4.2.act3')\n",
    "\n",
    "for param in test_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "test_model.eval()\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(n // 3 + 1, 3, i+1)\n",
    "    image_number = np.random.randint(len(val_dataset))\n",
    "    #image_number = i*20\n",
    "    test_image = val_dataset[image_number][0].unsqueeze(0)\n",
    "    test_label = val_dataset[image_number][1]\n",
    "\n",
    "    pred = test_model(test_image).softmax(1).argmax(1).item()\n",
    "    gradcam_result = 1-gradcam(test_image)\n",
    "\n",
    "    gradcam_overlay(test_image.squeeze(0).permute(1, 2, 0).to('cpu'), gradcam_result[0].squeeze(0).cpu().numpy(), opacity=0.25)\n",
    "    plt.title(f'ID: {image_number} | True: {test_label} | Pred: {pred}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(val_dataloader))\n",
    "test_preds = models[1](test_batch[0]).softmax(1).argmax(1)\n",
    "test_labels = test_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x180f2b5f590>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "labels = [0,1,2]\n",
    "classes = ('barcode', 'lung pulse', 'seashore')\n",
    "\n",
    "confmat = confusion_matrix(test_labels, test_preds, labels=labels)\n",
    "ConfusionMatrixDisplay(confmat, display_labels=labels).plot(cmap='Blues', colorbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, class_labels):\n",
    "    cf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "    \n",
    "    if cf_matrix.shape[0] < len(class_labels):\n",
    "        cf_matrix = np.pad(cf_matrix, (0, len(class_labels) - cf_matrix.shape[0]), 'constant')\n",
    "    \n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None],\n",
    "                         index = [i for i in class_labels],\n",
    "                         columns = [i for i in class_labels])\n",
    "    plt.figure(figsize = (7,7))\n",
    "    sn.heatmap(df_cm, annot=True, cmap='Blues', cbar=False)\n",
    "    #plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szabo\\anaconda3\\envs\\lung_us\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Repos\\PTX_ensemble_classifier\\general.py:85: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sensitivity_per_class[class_id] = padded_cf_matrix[class_id, class_id] / np.sum(padded_cf_matrix[class_id, :])\n",
      "d:\\Repos\\PTX_ensemble_classifier\\general.py:86: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  specificity_per_class[class_id] = padded_cf_matrix[class_id, class_id] / np.sum(padded_cf_matrix[:, class_id])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1., nan, nan]), array([ 1., nan, nan]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from general import get_metrics_from_confusion_matrix\n",
    "import torch\n",
    "\n",
    "y = torch.tensor([1,1,1,1])\n",
    "pred_y = torch.tensor([1,1,1,1])\n",
    "\n",
    "test = get_metrics_from_confusion_matrix(y, pred_y, 3)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 1.,  2.,  3.],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mat = np.array([[1, 2, 3],\n",
    "                [1,2,3],\n",
    "                [np.nan,np.nan,np.nan]])\n",
    "\n",
    "\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6261)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
